{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc02b48a-20b9-49a9-aaeb-86f1e7ccaff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b707a9-891b-4058-a166-f0f84b1a086a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3795b82-16ac-426f-8b9b-014aac5ee445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer le jeu de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af258ef6-8f3e-4255-9311-5ce36dd8e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Charger les images originales\n",
    "data_directory = \"C:/Users/Utilisateur/Documents/Python/python_Ynnov/Minst/mes_images\"\n",
    "image_files = os.listdir(data_directory)\n",
    "images = []\n",
    "labels = [0,1,2,3,4,5]\n",
    "\n",
    "for filename in image_files:\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        img = Image.open(os.path.join(data_directory, filename)).convert('L')  # Convertir en niveaux de gris\n",
    "        images.append(img)\n",
    "        \n",
    "# Redimensionner les images et appliquer la rotation pour augmenter les données\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "for iteration in range(260) :\n",
    "    for i, img in enumerate(images):\n",
    "        for angle in range(-21, 21): ## Pour incliner les images à droite et à gauche jusqu'à 20° \n",
    "            rotated_img = img.rotate(angle, resample=Image.BILINEAR, fillcolor=255)  # Appliquer la rotation\n",
    "            resized_img = rotated_img.resize((28, 28), Image.LANCZOS)  # Redimensionner l'image\n",
    "            augmented_images.append(np.array(resized_img))  # Convertir en tableau numpy\n",
    "            augmented_labels.append(labels[i])\n",
    "# A la fin de cette étape, le jeu de données comporte 104260 données.\n",
    "\n",
    "# Partitionner les données\n",
    "X_train, X_test, y_train, y_test = train_test_split(augmented_images, augmented_labels, test_size=0.2, random_state=42) # à partir du jeu de données de départ, sélectionner 80% des datas pour le jeu d'entraînement et 20% des datas pour le jeu de test.\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42) # scinder le jeu de test en deux parties égales, pour former un jeu de test et un jeu de validation.\n",
    "# A la fin de cette étape : \n",
    "    # Jeu de données d'entraînement : 83408 données\n",
    "    # Jeu de données de validation : 20852 données\n",
    "    # Jeu de données de test : 20852 données\n",
    "\n",
    "# Convertir en tableaux numpy\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Normaliser les valeurs des pixels (0-1)\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_val = X_val.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Ajouter une dimention par canal d'image\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_val = X_val[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38da2391-a449-4107-9661-82c34aad6450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les dimensions des ensembles de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9a1709f-5799-4ffc-98b2-681eaca7c9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions des ensembles d'entraînement, de validation et de test :\n",
      "Entraînement : (52416, 28, 28, 1) (52416,)\n",
      "Validation   : (6552, 28, 28, 1) (6552,)\n",
      "Test         : (6552, 28, 28, 1) (6552,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions des ensembles d'entraînement, de validation et de test :\")\n",
    "print(\"Entraînement :\", X_train.shape, y_train.shape)\n",
    "print(\"Validation   :\", X_val.shape, y_val.shape)\n",
    "print(\"Test         :\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b4c9cb-b79a-4455-b853-4ededa5837ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer une figure pour visualiser une partie du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "305c0ab7-778d-41b2-b597-bed7b456da20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAC4CAYAAAAPMYNWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAJZElEQVR4nO3dP2iV9xoH8JM2tmaLgkuwoFns5lAUJ3XRFgvVjha0FAcLwaqTLooOQhyCNCJosaNYaKqmgqYlFFEUEZN0qAit+AdFEER0EAcbc8d7L+f5ec97G32T83w+45eX+OaY38mXl/Pk6ZiamppqAAAk9E7dNwAAUBdFCABISxECANJShACAtBQhACAtRQgASEsRAgDSUoQAgLQUIQAgrc5WL+zo6HiT9wGV1f1H0Z0JZhpnAv5bK2fCEyEAIC1FCABISxECANJShACAtBQhACAtRQgASEsRAgDSUoQAgLQUIQAgLUUIAEhLEQIA0lKEAIC0FCEAIC1FCABISxECANJShACAtBQhACAtRQgASEsRAgDSUoQAgLQUIQAgLUUIAEhLEQIA0lKEAIC0FCEAIC1FCABISxECANJShACAtBQhACAtRQgASEsRAgDSUoQAgLQUIQAgrc66bwAA/lNHR0fL105NTb3BOyEDT4QAgLQUIQAgLUUIAEhLEQIA0lKEAIC0Uk+NVZlMaDRMJ5BXZ2f8VjE5ORnmzgr/xHT8/JTe32fDz6bfTW+XJ0IAQFqKEACQliIEAKSlCAEAaSlCAEBaqafGpuuT9u+8E/fJV69eTcvXh7r9/fffla4vnYmIc8KbUPX9va738WhCzBTY2+WJEACQliIEAKSlCAEAaSlCAEBaihAAkFZbTY1V3S3z4Ycfhnlpr9Iff/wR5lWmCuxsYiaoelY2bdoU5jdv3gzz69evt3wvpWmd0r04E7Ri/vz5Yf7kyZMwrzod9t5771X6OlXe47/++uvw2u7u7jDv7+8Pc1rjiRAAkJYiBACkpQgBAGkpQgBAWooQAJBWx1SLIxilKZOZpOqumPXr14f5mTNnwvzbb78N84mJiTA/e/ZsU1aaWKj6+pqcqf81mA1noqQ0vVjaKTYyMhLmq1evDvPBwcEw//XXX5uy0dHR8Fqqa/czUWUv1/79+8P8s88+C/NDhw6F+blz58L88ePHYV7VwMBAU/bJJ5+E1y5atCjMSxPQ9+/f/7/vq120ciY8EQIA0lKEAIC0FCEAIC1FCABISxECANJqq11jVScmogmWRqPRePjwYZhfuHAhzOfNmxfmJ06caMrGx8fDa/ft2xfmpf00pemMqvtyoBW//fZbmHd1dYX5d999F+a7du1qyrZt2xZee/jw4TAvncMSe/zaR5WpsRs3boT53r17w7y3tzfMjx49Gual3ZMXL14M876+vjB/+vRpU7Z06dLw2itXroT5xx9/HObHjx8P86oT1u3OEyEAIC1FCABISxECANJShACAtBQhACCttto1VlJ1r1Jp19jY2FiYl6ZbLl++3PK1x44dC/PS61761H/pe2pHdU/9zOYzUXVqZNWqVWFemuDasGFDmA8PDzdlpQmZ5cuXh/nQ0FCYR9M3jUauCUtn4t+6u7vDvDRNVpq8unXrVpiXdlVu3rw5zEsTXwcOHAjzyJEjR8K8p6cnzD///PMwzzQ1ZtcYAMBrKEIAQFqKEACQliIEAKSlCAEAaZkaC5SmAaLdYY1Go3Hz5s0wj3YoXb16Nby29Cn+0n9P3dMhM0Hdr8FsPhOley+9pqUJnEePHoX5+fPnw/z58+dN2dmzZ8Nrf/jhhzAvKZ2hkqwTMm/SbDgTo6OjYV7lfXw6Rb+fSr+b1qxZE+bff/99mC9ZsiTMX7x40eLdzX6mxgAAXkMRAgDSUoQAgLQUIQAgrfhTxG1mcnKy0vW//PJLmL/77rthPnfu3DD/9NNPm7IFCxaE15Y+MFqS6U+kM/1KHyAsfdi1tL7i3r17YV768Obvv//elO3evTu8duPGjWHe398f5qVBhNK5dVbaQ9X3wp9//jnMt27dGualM1H156p05qr8fir9jFddjTMyMhLmVYco2oUnQgBAWooQAJCWIgQApKUIAQBpKUIAQFopVmyUVF298dNPP4X5n3/+GeY//vhjU7Zjx47w2oULF4b5F198Eeal1QalSYbS9zSb1T3J4EyU186Urv/yyy9bvpfFixeH+fvvvx/mpXOYaU1N3d9THWei6qRTb29vmE9MTIT5Rx99FOa3bt2alvuZjq9x6tSpMH/w4EGYf/PNN2HejtPIVmwAALyGIgQApKUIAQBpKUIAQFqKEACQVopdYyVVPwl/+vTpMN+5c2eYHzx4sCnr7u4Ory3tNyvteCpNFczmT/cz+1y7di3Mv/rqq5a/RmkK7M6dO5XupR2n+Pjfqk7K3b59O8zv3r0b5uvWrQvzwcHBMK9jamx4eDjM9+zZE+bbt28P86y/PzwRAgDSUoQAgLQUIQAgLUUIAEhLEQIA0kq9a6yq0sRXadrg/v37Tdn+/fvDa4eGhirdS9X/j7p3EL0JdX9P7Xgmqu4aW7FiRZifO3cuzKP9Yc+ePQuvLe09yrQ7rKq6X4OZdCaq7s0aGBgI85UrV4b5smXLpuXfjVSdGvvggw/CvLQLcMuWLWH+119/tXB3s4tdYwAAr6EIAQBpKUIAQFqKEACQliIEAKSVetdYSelT/6W9X/v27QvzsbGxpuzSpUvhtXPmzAnzly9fhnnd0yG0p8nJyUrXj4+Ph3lfX1+Yl85WxHQY/0TVvVknT54M856enjDv6uoK8xcvXoR5lUmwqj/j0YRyo9ForF27ttK9ZOWJEACQliIEAKSlCAEAaSlCAEBaihAAkJZdY4E3ucer6nQYZXVPD2U6E8wOzsTbM5N24VXdTZaJXWMAAK+hCAEAaSlCAEBaihAAkJYiBACkZWpsGvjEfj3qfn2diTJnoh51v77OBDONqTEAgNdQhACAtBQhACAtRQgASEsRAgDS6qz7BtpB3ZMaMNM4E8Bs4YkQAJCWIgQApKUIAQBpKUIAQFqKEACQliIEAKSlCAEAaSlCAEBaihAAkJYiBACkpQgBAGkpQgBAWooQAJCWIgQApKUIAQBpKUIAQFqKEACQliIEAKSlCAEAaSlCAEBaihAAkJYiBACkpQgBAGkpQgBAWooQAJCWIgQApKUIAQBpKUIAQFqddd8AQHYdHR113wKk5YkQAJCWIgQApKUIAQBpKUIAQFqKEACQlqkxgJpNTU3VfQuQlidCAEBaihAAkJYiBACkpQgBAGkpQgBAWh1TxhUAgKQ8EQIA0lKEAIC0FCEAIC1FCABISxECANJShACAtBQhACAtRQgASEsRAgDS+hevG8ES7jeYowAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x240 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cathégorie image n° 0 :\n",
      "1\n",
      "cathégorie image n° 1 :\n",
      "0\n",
      "cathégorie image n° 2 :\n",
      "4\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "X_new = X_test[:3]\n",
    "y_new = y_test[:3]\n",
    "\n",
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.xlabel(y_new[index])\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()\n",
    "\n",
    "for index in range(3) :\n",
    "    print (\"cathégorie image n° \" + str(index) + \" :\") \n",
    "    print(y_new[index])\n",
    "\n",
    "print(y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f18d303-fea1-4109-b460-5566366e900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture du CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c6dd7a-2fa9-45df-93b2-de8e72a452eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=256),\n",
    "    DefaultConv2D(filters=256),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=6, activation='softmax'), # Ne pas oublier d'adapter le nombre de neurones en fonction du nombre de catégories dans le problème à résoudre. \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a48166d6-c4c3-4b2f-b6c9-ed8c284d5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher un résumé du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07731322-2b53-4b30-9b3e-1569d4e2ab95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        3200      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 3, 3, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               295040    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1413574 (5.39 MB)\n",
      "Trainable params: 1413574 (5.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22cc3c6d-7f31-424a-a14d-10b0ee1d7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c76522ac-513e-4524-97a7-0b84f8c50b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1638/1638 [==============================] - 261s 155ms/step - loss: 0.1352 - accuracy: 0.9451 - val_loss: 1.1390e-08 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1638/1638 [==============================] - 251s 153ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1638/1638 [==============================] - 251s 153ms/step - loss: 0.0317 - accuracy: 0.9963 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1638/1638 [==============================] - 252s 154ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1638/1638 [==============================] - 252s 154ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1638/1638 [==============================] - 252s 154ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 5.4204e-07 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1638/1638 [==============================] - 253s 154ms/step - loss: 0.0162 - accuracy: 0.9966 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1638/1638 [==============================] - 266s 162ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1638/1638 [==============================] - 268s 163ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1638/1638 [==============================] - 268s 164ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "205/205 [==============================] - 12s 59ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "728c1309-d223-49ec-9c46-386cd01c7c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7debd208-8e1a-44b9-9516-27fee01f2740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "class: [0 , 1 , 2 , 3 , 4 , 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_new = y_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "print(\"class: [0 , 1 , 2 , 3 , 4 , 5]\") \n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e78cf43-6b37-407e-a0e6-76684aae1c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x240 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cathégorie image n° 0 :\n",
      "1\n",
      "cathégorie image n° 1 :\n",
      "0\n",
      "cathégorie image n° 2 :\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.xlabel(y_new[index])\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()\n",
    "\n",
    "for index in range(3) :\n",
    "    print (\"cathégorie image n° \" + str(index) + \" :\") \n",
    "    print(y_new[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743bddf8-5a80-4a3c-b439-c8972c408c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
