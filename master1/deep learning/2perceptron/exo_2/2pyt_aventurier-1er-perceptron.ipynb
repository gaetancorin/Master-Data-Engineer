{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d05a573-65c0-4a58-a629-2b003f2918d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires au programme\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c365132b-0e62-4ca2-8379-cd64f72c1b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa2df8b-8767-47e2-82be-8a89bffae03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les données servant à entraîner l'IA \n",
    "# c'est à dire les compagnies se présentant aléatoirement à l'entrée du donjon \n",
    "\n",
    "## pour simplifier, une compagnie sera représentée par la somme des puissances \n",
    "# des aventuriers qui la compose\n",
    "\n",
    "# aventurier_1\taventurier_2\taventurier_3\tpuissance\n",
    "# belette\t    belette\t        belette\t        24\n",
    "# belette\t    belette         chevalier\t    27\n",
    "# chevalier\t    chevalier\t    belette\t        30\n",
    "# belette\t    belette\t        elfe\t        31\n",
    "# chevalier\t    chevalier\t    chevalier\t    33\n",
    "# chevalier   \telfe\t        belette\t        34\n",
    "# chevalier  \tchevalier\t    elfe\t        37\n",
    "# elfe\t        elfe\t        belette\t        38\n",
    "# elfe\t        elfe\t        chevalier       41\n",
    "# elfe\t        elfe\t        elfe\t        45\n",
    "\n",
    "## shéma du perceptron : \n",
    "# puissance de la compagnie ------poids de la compagnie-----neurone------>prediction\n",
    "# poids de la sorcière (biais) -------------------------------|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcbc0564-10dd-4007-b103-c26ef2cd5f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compagnie_faible [31, 24, 33, 31, 31, 33, 33, 31, 33, 27, 27, 33, 31, 31, 30, 30, 30, 33, 30, 30, 30, 30, 24, 30, 27, 30, 33, 24, 24, 24, 24, 31, 30, 27, 27, 30, 24, 31, 30, 33, 27, 24, 27, 27, 31, 33, 30, 24, 27, 24, 30, 33, 33, 33, 27, 24, 31, 30, 33, 33, 27, 30, 27, 24, 33, 30, 33, 24, 24, 27, 30, 33, 30, 24, 24, 27, 30, 31, 31, 24, 24, 24, 27, 30, 31, 24, 30, 30, 24, 27, 27, 30, 30, 24, 30, 27, 31, 24, 27, 24]\n",
      "compagnie_forte [41, 45, 45, 38, 41, 34, 34, 45, 38, 41, 41, 45, 38, 38, 34, 37, 41, 37, 41, 45, 37, 41, 41, 45, 41, 34, 41, 34, 34, 37, 45, 34, 45, 41, 41, 41, 38, 38, 37, 37, 37, 41, 41, 34, 34, 41, 45, 45, 45, 45, 41, 45, 37, 45, 38, 41, 34, 41, 41, 37, 38, 41, 37, 41, 41, 37, 41, 34, 41, 34, 41, 34, 38, 41, 37, 41, 41, 45, 38, 37, 41, 38, 34, 37, 34, 38, 45, 41, 38, 37, 41, 38, 34, 41, 34, 38, 37, 45, 45, 41]\n"
     ]
    }
   ],
   "source": [
    "possibility_compagnie_faible = [24,27,30,31,33]\n",
    "compagnie_faible = []\n",
    "for i in range(100):\n",
    "    compagnie_faible.append(random.choice(possibility_compagnie_faible))\n",
    "\n",
    "print('compagnie_faible', compagnie_faible)\n",
    "\n",
    "possibility_compagnie_forte = [34,37,38,41,45]\n",
    "compagnie_forte = []\n",
    "for i in range(100):\n",
    "    compagnie_forte.append(random.choice(possibility_compagnie_forte))\n",
    "print('compagnie_forte', compagnie_forte)\n",
    "\n",
    "\n",
    "# compagnie_faible = [24,27,30,31,33] * 10\n",
    "# print(compagnie_faible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f09c26-f11e-40d9-baf2-1efbc1c3da2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Définir les étiquettes des données d'entraînement : \n",
    "# 0 = envoyer un troll\n",
    "# 1 = envoyer deux trolls\n",
    "\n",
    "etiquettes_zeros_like = np.zeros_like(compagnie_faible)\n",
    "print(etiquettes_zeros_like)\n",
    "etiquettes_one_like = np.ones_like(compagnie_forte)\n",
    "print(etiquettes_one_like)\n",
    "#? indice : zero_like()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d9e6bb9-845c-4a12-9bbe-30c459d48a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31 24 33 31 31 33 33 31 33 27 27 33 31 31 30 30 30 33 30 30 30 30 24 30\n",
      " 27 30 33 24 24 24 24 31 30 27 27 30 24 31 30 33 27 24 27 27 31 33 30 24\n",
      " 27 24 30 33 33 33 27 24 31 30 33 33 27 30 27 24 33 30 33 24 24 27 30 33\n",
      " 30 24 24 27 30 31 31 24 24 24 27 30 31 24 30 30 24 27 27 30 30 24 30 27\n",
      " 31 24 27 24 41 45 45 38 41 34 34 45 38 41 41 45 38 38 34 37 41 37 41 45\n",
      " 37 41 41 45 41 34 41 34 34 37 45 34 45 41 41 41 38 38 37 37 37 41 41 34\n",
      " 34 41 45 45 45 45 41 45 37 45 38 41 34 41 41 37 38 41 37 41 41 37 41 34\n",
      " 41 34 41 34 38 41 37 41 41 45 38 37 41 38 34 37 34 38 45 41 38 37 41 38\n",
      " 34 41 34 38 37 45 45 41]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Concaténer les données et les étiquettes\n",
    "donnees_entree = np.concatenate((compagnie_faible, compagnie_forte), axis=0)\n",
    "print(donnees_entree)\n",
    "\n",
    "etiquettes = np.concatenate((etiquettes_zeros_like, etiquettes_one_like), axis=0)\n",
    "print(etiquettes)\n",
    "\n",
    "#? indice : np.concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb7a566-0635-4233-ba14-a1676d980db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mélanger les données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b84799b-11b1-4a96-8594-73e087e12287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24 30 33 41 41 24 38 41 24 45 41 31 33 41 45 38 45 33 45 38 27 30 41 31\n",
      " 34 30 33 45 41 34 24 41 34 37 30 41 38 34 41 30 27 24 30 33 45 37 37 34\n",
      " 45 24 30 38 24 27 27 33 31 41 41 34 45 30 38 24 30 34 30 38 33 30 37 24\n",
      " 37 30 27 33 34 27 34 27 38 45 45 27 41 41 45 33 45 27 30 41 41 34 37 41\n",
      " 30 45 34 37 31 30 38 41 33 34 37 30 30 31 31 24 30 41 41 31 34 31 45 24\n",
      " 24 37 38 41 38 24 27 27 33 31 24 41 27 30 24 24 31 41 34 30 41 45 30 45\n",
      " 41 30 34 41 30 27 24 37 37 41 41 33 33 31 41 41 37 38 24 45 41 27 34 45\n",
      " 41 41 37 27 24 33 27 30 37 38 27 37 41 30 31 37 27 24 30 24 24 27 24 33\n",
      " 33 38 31 31 38 34 33 24]\n",
      "[0 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 0 1 1\n",
      " 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0\n",
      " 0 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0\n",
      " 0 0 1 1 0 1 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 1\n",
      " 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "indices_melanges = np.random.permutation(len(donnees_entree))\n",
    "donnees_entree = donnees_entree[indices_melanges]\n",
    "print(donnees_entree)\n",
    "etiquettes = etiquettes[indices_melanges]\n",
    "print(etiquettes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7489ac1-cf1e-4092-93cd-dfe7a44182da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le modèle\n",
    "\n",
    "## Sequential() est une architecture de perceptron bien adaptée à la classification binaire\n",
    "## modele.add(Dense(1, input_dim=1, activation='sigmoid'))\n",
    "## permet de former un modèle avec 1 couche (1 neurone), recevant une seule donnée (input_dim=1)\n",
    "## la fonction d'activation du modèle est la fonction sigmoide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37d0477f-a11d-4d7f-b955-06135b404d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaeta\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "modele = Sequential()\n",
    "modele.add(Dense(1, input_dim=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc581fc3-0e72-4601-bba6-1c118f99d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le modèle\n",
    "## optimizer désigne l'algorithme en charge de la modification des poids \n",
    "## loss mesure la distance entre la prediction du neurone et le résultat souhaité\n",
    "## ici nous utilisons l'algorithme 'binary_crossentropy' car nous voulons distinguer 2 groupes\n",
    "## metrics indique, sur une échelle de 0 à 1, le ratio de prédictions correctes pour un cycle d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3604ebd0-2d0b-4375-a3e5-168361a57c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modele.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67078ed6-eb63-4031-ad47-57c874a57a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner le modèle\n",
    "## ce sera à vous de rechercher comment fonctionne cette commande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85c6ec8b-5fba-4ed5-af1f-016740986112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - accuracy: 0.5263 - loss: 9.3635   \n",
      "Epoch 2/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.5237 - loss: 6.8011 \n",
      "Epoch 3/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.5014 - loss: 4.2653  \n",
      "Epoch 4/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.5049 - loss: 1.6138\n",
      "Epoch 5/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.4302 - loss: 0.7305\n",
      "Epoch 6/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.4561 - loss: 0.7334 \n",
      "Epoch 7/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.4863 - loss: 0.7255\n",
      "Epoch 8/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.5724 - loss: 0.6900\n",
      "Epoch 9/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - accuracy: 0.5632 - loss: 0.7060\n",
      "Epoch 10/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.4885 - loss: 0.7177 \n",
      "Epoch 11/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.4847 - loss: 0.7181\n",
      "Epoch 12/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.3404 - loss: 0.7271\n",
      "Epoch 13/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.5227 - loss: 0.7023 \n",
      "Epoch 14/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.4997 - loss: 0.6997 \n",
      "Epoch 15/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.4989 - loss: 0.7065\n",
      "Epoch 16/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.5173 - loss: 0.6959\n",
      "Epoch 17/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.4993 - loss: 0.7036 \n",
      "Epoch 18/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.5152 - loss: 0.6904\n",
      "Epoch 19/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.5151 - loss: 0.6932 \n",
      "Epoch 20/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.5389 - loss: 0.6838\n",
      "Epoch 21/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.4403 - loss: 0.7021 \n",
      "Epoch 22/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.4596 - loss: 0.7061\n",
      "Epoch 23/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.4891 - loss: 0.6919\n",
      "Epoch 24/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.4917 - loss: 0.6873\n",
      "Epoch 25/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.4892 - loss: 0.6840\n",
      "Epoch 26/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.5643 - loss: 0.6568 \n",
      "Epoch 27/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.4943 - loss: 0.6806\n",
      "Epoch 28/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.4548 - loss: 0.6882\n",
      "Epoch 29/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.5152 - loss: 0.6663\n",
      "Epoch 30/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.5058 - loss: 0.6685 \n",
      "Epoch 31/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.5084 - loss: 0.6756 \n",
      "Epoch 32/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.5191 - loss: 0.6599 \n",
      "Epoch 33/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.5594 - loss: 0.6675\n",
      "Epoch 34/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.5040 - loss: 0.6585 \n",
      "Epoch 35/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.5066 - loss: 0.6628 \n",
      "Epoch 36/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.5118 - loss: 0.6716\n",
      "Epoch 37/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.4913 - loss: 0.6646 \n",
      "Epoch 38/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.5190 - loss: 0.6624\n",
      "Epoch 39/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.4953 - loss: 0.6542 \n",
      "Epoch 40/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 0.7737 - loss: 0.6553\n",
      "Epoch 41/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.5562 - loss: 0.6569\n",
      "Epoch 42/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.5011 - loss: 0.6515\n",
      "Epoch 43/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.5418 - loss: 0.6288\n",
      "Epoch 44/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.6166 - loss: 0.6432\n",
      "Epoch 45/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.5701 - loss: 0.6320\n",
      "Epoch 46/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.5401 - loss: 0.6581\n",
      "Epoch 47/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.5893 - loss: 0.6379 \n",
      "Epoch 48/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.5472 - loss: 0.6474\n",
      "Epoch 49/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - accuracy: 0.5619 - loss: 0.6323\n",
      "Epoch 50/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.5779 - loss: 0.6170\n",
      "Epoch 51/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.6534 - loss: 0.6318\n",
      "Epoch 52/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.6533 - loss: 0.6428\n",
      "Epoch 53/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.5894 - loss: 0.6212 \n",
      "Epoch 54/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.8005 - loss: 0.6252\n",
      "Epoch 55/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.6498 - loss: 0.6272 \n",
      "Epoch 56/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - accuracy: 0.6322 - loss: 0.6013\n",
      "Epoch 57/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.6422 - loss: 0.6218 \n",
      "Epoch 58/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.6595 - loss: 0.6065 \n",
      "Epoch 59/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.6347 - loss: 0.6040\n",
      "Epoch 60/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 0.6418 - loss: 0.6212 \n",
      "Epoch 61/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.6869 - loss: 0.5994\n",
      "Epoch 62/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.6853 - loss: 0.5906 \n",
      "Epoch 63/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7706 - loss: 0.6031 \n",
      "Epoch 64/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7288 - loss: 0.5978\n",
      "Epoch 65/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7094 - loss: 0.6038\n",
      "Epoch 66/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.7455 - loss: 0.5914\n",
      "Epoch 67/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7719 - loss: 0.5921\n",
      "Epoch 68/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7263 - loss: 0.5930 \n",
      "Epoch 69/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6908 - loss: 0.5884 \n",
      "Epoch 70/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.6878 - loss: 0.5800 \n",
      "Epoch 71/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - accuracy: 0.7220 - loss: 0.5900\n",
      "Epoch 72/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.6831 - loss: 0.6014 \n",
      "Epoch 73/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7044 - loss: 0.5925\n",
      "Epoch 74/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6972 - loss: 0.5936 \n",
      "Epoch 75/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.6704 - loss: 0.5935\n",
      "Epoch 76/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7300 - loss: 0.5792\n",
      "Epoch 77/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7575 - loss: 0.5738\n",
      "Epoch 78/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7821 - loss: 0.5701\n",
      "Epoch 79/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.7920 - loss: 0.5723 \n",
      "Epoch 80/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.8369 - loss: 0.5835\n",
      "Epoch 81/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - accuracy: 0.7205 - loss: 0.5585\n",
      "Epoch 82/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.8516 - loss: 0.5684\n",
      "Epoch 83/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - accuracy: 0.6847 - loss: 0.5704 \n",
      "Epoch 84/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.8769 - loss: 0.5687\n",
      "Epoch 85/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.8454 - loss: 0.5570\n",
      "Epoch 86/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7960 - loss: 0.5629\n",
      "Epoch 87/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7629 - loss: 0.5310\n",
      "Epoch 88/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.8208 - loss: 0.5657\n",
      "Epoch 89/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.9277 - loss: 0.5623\n",
      "Epoch 90/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.8130 - loss: 0.5578\n",
      "Epoch 91/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.7567 - loss: 0.5444\n",
      "Epoch 92/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.8465 - loss: 0.5508\n",
      "Epoch 93/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.7526 - loss: 0.5096\n",
      "Epoch 94/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.9041 - loss: 0.5552\n",
      "Epoch 95/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7302 - loss: 0.5465\n",
      "Epoch 96/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7887 - loss: 0.5335 \n",
      "Epoch 97/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.7808 - loss: 0.5251\n",
      "Epoch 98/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.8862 - loss: 0.5444\n",
      "Epoch 99/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.8880 - loss: 0.5278\n",
      "Epoch 100/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.8226 - loss: 0.5528\n",
      "Epoch 101/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.8290 - loss: 0.5614\n",
      "Epoch 102/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.8069 - loss: 0.5641 \n",
      "Epoch 103/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.7751 - loss: 0.5238\n",
      "Epoch 104/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.9087 - loss: 0.5266\n",
      "Epoch 105/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.9376 - loss: 0.5351\n",
      "Epoch 106/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7525 - loss: 0.5346\n",
      "Epoch 107/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.8529 - loss: 0.5273 \n",
      "Epoch 108/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.7963 - loss: 0.5194\n",
      "Epoch 109/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.8839 - loss: 0.5279\n",
      "Epoch 110/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - accuracy: 0.8023 - loss: 0.5154\n",
      "Epoch 111/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.9162 - loss: 0.5139\n",
      "Epoch 112/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.7553 - loss: 0.5249 \n",
      "Epoch 113/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.8793 - loss: 0.5113\n",
      "Epoch 114/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.9157 - loss: 0.5218\n",
      "Epoch 115/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.8549 - loss: 0.4870\n",
      "Epoch 116/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9113 - loss: 0.5219\n",
      "Epoch 117/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.8192 - loss: 0.5017\n",
      "Epoch 118/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.8751 - loss: 0.5216\n",
      "Epoch 119/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7925 - loss: 0.5204\n",
      "Epoch 120/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.8558 - loss: 0.5039\n",
      "Epoch 121/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.9511 - loss: 0.5166\n",
      "Epoch 122/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.9030 - loss: 0.5093\n",
      "Epoch 123/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.8318 - loss: 0.5234\n",
      "Epoch 124/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.8285 - loss: 0.4863\n",
      "Epoch 125/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.9004 - loss: 0.5100\n",
      "Epoch 126/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.9240 - loss: 0.4994\n",
      "Epoch 127/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.8156 - loss: 0.4800\n",
      "Epoch 128/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - accuracy: 0.8650 - loss: 0.4789\n",
      "Epoch 129/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.9022 - loss: 0.4958\n",
      "Epoch 130/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - accuracy: 0.8741 - loss: 0.5032\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - accuracy: 0.9050 - loss: 0.4760\n",
      "Epoch 132/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.8778 - loss: 0.4801\n",
      "Epoch 133/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.9306 - loss: 0.4938\n",
      "Epoch 134/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8682 - loss: 0.4794\n",
      "Epoch 135/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - accuracy: 0.8851 - loss: 0.4986\n",
      "Epoch 136/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.8847 - loss: 0.4922\n",
      "Epoch 137/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 0.9170 - loss: 0.4965\n",
      "Epoch 138/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.7828 - loss: 0.4917\n",
      "Epoch 139/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.8813 - loss: 0.5036\n",
      "Epoch 140/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 0.9247 - loss: 0.4792\n",
      "Epoch 141/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.9245 - loss: 0.4730\n",
      "Epoch 142/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.9372 - loss: 0.4703\n",
      "Epoch 143/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.9262 - loss: 0.4865\n",
      "Epoch 144/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.8683 - loss: 0.4515\n",
      "Epoch 145/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.8871 - loss: 0.4700\n",
      "Epoch 146/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.9288 - loss: 0.4760\n",
      "Epoch 147/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.9445 - loss: 0.4699\n",
      "Epoch 148/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.9178 - loss: 0.4694\n",
      "Epoch 149/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.9053 - loss: 0.4831\n",
      "Epoch 150/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.9646 - loss: 0.4770\n",
      "Epoch 151/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.8367 - loss: 0.4468\n",
      "Epoch 152/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.9361 - loss: 0.4537\n",
      "Epoch 153/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.9594 - loss: 0.4567\n",
      "Epoch 154/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.9172 - loss: 0.4582\n",
      "Epoch 155/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.9036 - loss: 0.4594\n",
      "Epoch 156/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.9088 - loss: 0.4685\n",
      "Epoch 157/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.8938 - loss: 0.4316\n",
      "Epoch 158/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.9315 - loss: 0.4482\n",
      "Epoch 159/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.8770 - loss: 0.4663 \n",
      "Epoch 160/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 0.9472 - loss: 0.4323\n",
      "Epoch 161/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.9181 - loss: 0.4551\n",
      "Epoch 162/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.9257 - loss: 0.4526\n",
      "Epoch 163/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.9139 - loss: 0.4684\n",
      "Epoch 164/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - accuracy: 0.9129 - loss: 0.4475\n",
      "Epoch 165/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.9542 - loss: 0.4483\n",
      "Epoch 166/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.8918 - loss: 0.4394\n",
      "Epoch 167/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.9317 - loss: 0.4504\n",
      "Epoch 168/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.9196 - loss: 0.4423\n",
      "Epoch 169/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.8622 - loss: 0.4496 \n",
      "Epoch 170/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.9622 - loss: 0.4476\n",
      "Epoch 171/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.9025 - loss: 0.4423\n",
      "Epoch 172/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.8979 - loss: 0.4338\n",
      "Epoch 173/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 0.9298 - loss: 0.4360\n",
      "Epoch 174/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.9149 - loss: 0.4266\n",
      "Epoch 175/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 0.9675 - loss: 0.4304\n",
      "Epoch 176/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.8689 - loss: 0.4326\n",
      "Epoch 177/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.9617 - loss: 0.4324\n",
      "Epoch 178/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.9065 - loss: 0.4431\n",
      "Epoch 179/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.8429 - loss: 0.4066\n",
      "Epoch 180/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.9046 - loss: 0.4508 \n",
      "Epoch 181/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.9527 - loss: 0.4199\n",
      "Epoch 182/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.9350 - loss: 0.4305\n",
      "Epoch 183/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - accuracy: 0.9338 - loss: 0.4339\n",
      "Epoch 184/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9004 - loss: 0.4355\n",
      "Epoch 185/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.9538 - loss: 0.4173\n",
      "Epoch 186/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.9292 - loss: 0.4369\n",
      "Epoch 187/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.9176 - loss: 0.4116\n",
      "Epoch 188/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.9795 - loss: 0.4113\n",
      "Epoch 189/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.9225 - loss: 0.4030\n",
      "Epoch 190/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.9354 - loss: 0.4325\n",
      "Epoch 191/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - accuracy: 0.8847 - loss: 0.4352\n",
      "Epoch 192/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.9112 - loss: 0.4258\n",
      "Epoch 193/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9263 - loss: 0.4344\n",
      "Epoch 194/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.8723 - loss: 0.4518\n",
      "Epoch 195/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.9457 - loss: 0.4125\n",
      "Epoch 196/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.9263 - loss: 0.4220\n",
      "Epoch 197/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 0.9249 - loss: 0.4197\n",
      "Epoch 198/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.9556 - loss: 0.4006\n",
      "Epoch 199/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.9359 - loss: 0.4243\n",
      "Epoch 200/200\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.9412 - loss: 0.4192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a8b6ac5650>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele.fit(donnees_entree, etiquettes, epochs=200, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f3eee76-8a9e-4343-a8c8-a838690b6972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "196eefe8-1efa-4877-9ab4-2a84aa2c9a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 0.4027 \n",
      "Perte : 0.4197976589202881, Précision : 0.9150000214576721\n"
     ]
    }
   ],
   "source": [
    "perte, precision = modele.evaluate(donnees_entree, etiquettes)\n",
    "print(f\"Perte : {perte}, Précision : {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "146d553c-5d5b-4a7e-846a-7b063a9b9318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24 30 33 41 41 24 38 41 24 45 41 31 33 41 45 38 45 33 45 38 27 30 41 31\n",
      " 34 30 33 45 41 34 24 41 34 37 30 41 38 34 41 30 27 24 30 33 45 37 37 34\n",
      " 45 24 30 38 24 27 27 33 31 41 41 34 45 30 38 24 30 34 30 38 33 30 37 24\n",
      " 37 30 27 33 34 27 34 27 38 45 45 27 41 41 45 33 45 27 30 41 41 34 37 41\n",
      " 30 45 34 37 31 30 38 41 33 34 37 30 30 31 31 24 30 41 41 31 34 31 45 24\n",
      " 24 37 38 41 38 24 27 27 33 31 24 41 27 30 24 24 31 41 34 30 41 45 30 45\n",
      " 41 30 34 41 30 27 24 37 37 41 41 33 33 31 41 41 37 38 24 45 41 27 34 45\n",
      " 41 41 37 27 24 33 27 30 37 38 27 37 41 30 31 37 27 24 30 24 24 27 24 33\n",
      " 33 38 31 31 38 34 33 24]\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.22943188],\n",
       "       [0.41787452],\n",
       "       [0.5270994 ],\n",
       "       [0.7827663 ],\n",
       "       [0.7827663 ],\n",
       "       [0.22943188],\n",
       "       [0.69885504],\n",
       "       [0.7827663 ],\n",
       "       [0.22943188],\n",
       "       [0.8662891 ],\n",
       "       [0.7827663 ],\n",
       "       [0.45392233],\n",
       "       [0.5270994 ],\n",
       "       [0.7827663 ],\n",
       "       [0.8662891 ],\n",
       "       [0.69885504],\n",
       "       [0.8662891 ],\n",
       "       [0.5270994 ],\n",
       "       [0.8662891 ],\n",
       "       [0.69885504],\n",
       "       [0.31615186],\n",
       "       [0.41787452],\n",
       "       [0.7827663 ],\n",
       "       [0.45392233],\n",
       "       [0.5634495 ],\n",
       "       [0.41787452],\n",
       "       [0.5270994 ],\n",
       "       [0.8662891 ],\n",
       "       [0.7827663 ],\n",
       "       [0.5634495 ],\n",
       "       [0.22943188],\n",
       "       [0.7827663 ],\n",
       "       [0.5634495 ],\n",
       "       [0.6671188 ],\n",
       "       [0.41787452],\n",
       "       [0.7827663 ],\n",
       "       [0.69885504],\n",
       "       [0.5634495 ],\n",
       "       [0.7827663 ],\n",
       "       [0.41787452],\n",
       "       [0.31615186],\n",
       "       [0.22943188],\n",
       "       [0.41787452],\n",
       "       [0.5270994 ],\n",
       "       [0.8662891 ],\n",
       "       [0.6671188 ],\n",
       "       [0.6671188 ],\n",
       "       [0.5634495 ],\n",
       "       [0.8662891 ],\n",
       "       [0.22943188],\n",
       "       [0.41787452],\n",
       "       [0.69885504],\n",
       "       [0.22943188],\n",
       "       [0.31615186],\n",
       "       [0.31615186],\n",
       "       [0.5270994 ],\n",
       "       [0.45392233],\n",
       "       [0.7827663 ],\n",
       "       [0.7827663 ],\n",
       "       [0.5634495 ],\n",
       "       [0.8662891 ],\n",
       "       [0.41787452],\n",
       "       [0.69885504],\n",
       "       [0.22943188],\n",
       "       [0.41787452],\n",
       "       [0.5634495 ],\n",
       "       [0.41787452],\n",
       "       [0.69885504],\n",
       "       [0.5270994 ],\n",
       "       [0.41787452],\n",
       "       [0.6671188 ],\n",
       "       [0.22943188],\n",
       "       [0.6671188 ],\n",
       "       [0.41787452],\n",
       "       [0.31615186],\n",
       "       [0.5270994 ],\n",
       "       [0.5634495 ],\n",
       "       [0.31615186],\n",
       "       [0.5634495 ],\n",
       "       [0.31615186],\n",
       "       [0.69885504],\n",
       "       [0.8662891 ],\n",
       "       [0.8662891 ],\n",
       "       [0.31615186],\n",
       "       [0.7827663 ],\n",
       "       [0.7827663 ],\n",
       "       [0.8662891 ],\n",
       "       [0.5270994 ],\n",
       "       [0.8662891 ],\n",
       "       [0.31615186],\n",
       "       [0.41787452],\n",
       "       [0.7827663 ],\n",
       "       [0.7827663 ],\n",
       "       [0.5634495 ],\n",
       "       [0.6671188 ],\n",
       "       [0.7827663 ],\n",
       "       [0.41787452],\n",
       "       [0.8662891 ],\n",
       "       [0.5634495 ],\n",
       "       [0.6671188 ],\n",
       "       [0.45392233],\n",
       "       [0.41787452],\n",
       "       [0.69885504],\n",
       "       [0.7827663 ],\n",
       "       [0.5270994 ],\n",
       "       [0.5634495 ],\n",
       "       [0.6671188 ],\n",
       "       [0.41787452],\n",
       "       [0.41787452],\n",
       "       [0.45392233],\n",
       "       [0.45392233],\n",
       "       [0.22943188],\n",
       "       [0.41787452],\n",
       "       [0.7827663 ],\n",
       "       [0.7827663 ],\n",
       "       [0.45392233],\n",
       "       [0.5634495 ],\n",
       "       [0.45392233],\n",
       "       [0.8662891 ],\n",
       "       [0.22943188],\n",
       "       [0.22943188],\n",
       "       [0.6671188 ],\n",
       "       [0.69885504],\n",
       "       [0.7827663 ],\n",
       "       [0.69885504],\n",
       "       [0.22943188],\n",
       "       [0.31615186],\n",
       "       [0.31615186],\n",
       "       [0.5270994 ],\n",
       "       [0.45392233],\n",
       "       [0.22943188],\n",
       "       [0.7827663 ],\n",
       "       [0.31615186],\n",
       "       [0.41787452],\n",
       "       [0.22943188],\n",
       "       [0.22943188],\n",
       "       [0.45392233],\n",
       "       [0.7827663 ],\n",
       "       [0.5634495 ],\n",
       "       [0.41787452],\n",
       "       [0.7827663 ],\n",
       "       [0.8662891 ],\n",
       "       [0.41787452],\n",
       "       [0.8662891 ],\n",
       "       [0.7827663 ],\n",
       "       [0.41787452],\n",
       "       [0.5634495 ],\n",
       "       [0.7827663 ],\n",
       "       [0.41787452],\n",
       "       [0.31615186],\n",
       "       [0.22943188],\n",
       "       [0.6671188 ],\n",
       "       [0.6671188 ],\n",
       "       [0.7827663 ],\n",
       "       [0.7827663 ],\n",
       "       [0.5270994 ],\n",
       "       [0.5270994 ],\n",
       "       [0.45392233],\n",
       "       [0.7827663 ],\n",
       "       [0.7827663 ],\n",
       "       [0.6671188 ],\n",
       "       [0.69885504],\n",
       "       [0.22943188],\n",
       "       [0.8662891 ],\n",
       "       [0.7827663 ],\n",
       "       [0.31615186],\n",
       "       [0.5634495 ],\n",
       "       [0.8662891 ],\n",
       "       [0.7827663 ],\n",
       "       [0.7827663 ],\n",
       "       [0.6671188 ],\n",
       "       [0.31615186],\n",
       "       [0.22943188],\n",
       "       [0.5270994 ],\n",
       "       [0.31615186],\n",
       "       [0.41787452],\n",
       "       [0.6671188 ],\n",
       "       [0.69885504],\n",
       "       [0.31615186],\n",
       "       [0.6671188 ],\n",
       "       [0.7827663 ],\n",
       "       [0.41787452],\n",
       "       [0.45392233],\n",
       "       [0.6671188 ],\n",
       "       [0.31615186],\n",
       "       [0.22943188],\n",
       "       [0.41787452],\n",
       "       [0.22943188],\n",
       "       [0.22943188],\n",
       "       [0.31615186],\n",
       "       [0.22943188],\n",
       "       [0.5270994 ],\n",
       "       [0.5270994 ],\n",
       "       [0.69885504],\n",
       "       [0.45392233],\n",
       "       [0.45392233],\n",
       "       [0.69885504],\n",
       "       [0.5634495 ],\n",
       "       [0.5270994 ],\n",
       "       [0.22943188]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demander à afficher les prédictions associées à chaque compagnie\n",
    "# Si la prédiction est > à 0.5, cela signifie que la compagnie est dangereuse\n",
    "print(donnees_entree)\n",
    "modele.predict(donnees_entree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "292b8d55-d2fa-48a3-b600-78d6f373af9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5730154"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pouvez-vous en déduire l'équation utilisée dans ce modèle,\n",
    "# pour déterminer la valeur du \"x\" qui est transmis à la \n",
    "# fonction d'activation sigmoide ? \n",
    "# non\n",
    "# force compagnie:\n",
    "#38\n",
    "# poids:\n",
    "# -0.00418886\n",
    "# 0.45334148\n",
    "# resultat\n",
    "0.5730154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3900c122-30c3-4618-accf-c896236617c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher, pour les 10 premières compagnies qui se présentent au donjon :\n",
    "    # La puissance des compagnies\n",
    "    # les étiquettes associées (0 ou 1)\n",
    "    # les prédictions, \n",
    "    # et la décision à prendre, en chaine de caractère"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "993a30c5-5d6e-42f5-925d-2d9eaee01886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "[[0.22943188]\n",
      " [0.41787452]\n",
      " [0.5270994 ]\n",
      " [0.7827663 ]\n",
      " [0.7827663 ]\n",
      " [0.22943188]\n",
      " [0.69885504]\n",
      " [0.7827663 ]\n",
      " [0.22943188]\n",
      " [0.8662891 ]]\n",
      "[0 0 0 1 1 0 1 1 0 1]\n",
      "['1 troll', '1 troll', '2 troll', '2 troll', '2 troll', '1 troll', '2 troll', '2 troll', '1 troll', '2 troll']\n"
     ]
    }
   ],
   "source": [
    "predictions = modele.predict(donnees_entree)\n",
    "resultat = []\n",
    "for i in range(10) :\n",
    "    if predictions[i] < 0.5 :\n",
    "        resultat.append('1 troll')\n",
    "    else :\n",
    "        resultat.append('2 troll')\n",
    "\n",
    "print(predictions[0:10])\n",
    "print(etiquettes[0:10])\n",
    "print(resultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce62a1c5-825b-410b-a91d-a9e878b98616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les poids du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3023391c-a85a-41c7-afa5-1d818739cf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'sequential/dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[0.14666954]], dtype=float32)>\n",
      "<tf.Variable 'sequential/dense/bias:0' shape=(1,) dtype=float32, numpy=array([-4.7315907], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "multiple_poids = modele.weights\n",
    "for poids in multiple_poids:\n",
    "    print(poids.value)\n",
    "\n",
    "# weights = [np.array(weight) for weight in modele.weights]\n",
    "\n",
    "# # Afficher les poids\n",
    "# for i, weight_array in enumerate(weights):\n",
    "#     print(f\"Poids {i + 1}:\")\n",
    "#     print(weight_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98eb247a-74bb-480b-8b49-c99524338ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les informations résumées relatives au modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d64f575c-2182-4ff0-960d-8984b73e279a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m2\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (28.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6\u001b[0m (28.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modele.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3c5a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
